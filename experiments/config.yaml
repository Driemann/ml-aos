model:
  n_meta_layers: 3
data:
  batch_size: 256
  num_workers: 16
  persistent_workers: true
  pin_memory: true
optimizer:
  class_path: torch.optim.Adam
  init_args:
    lr: 0.0003
trainer:
  num_nodes: 1
  gpus: 1
  strategy: ddp_find_unused_parameters_false
  sync_batchnorm: true

  max_epochs: 100
  max_time: null

  check_val_every_n_epoch: 1
  log_every_n_steps: 50

  overfit_batches: 0.0
  fast_dev_run: false

  precision: 16
  benchmark: true

  profiler: null
  deterministic: false

  callbacks:
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        save_top_k: 2
        monitor: val_loss
        mode: min
    #- class_path: pytorch_lightning.callbacks.StochasticWeightAveraging

ckpt_path: null
seed_everything: 123
